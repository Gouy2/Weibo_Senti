{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./local_model/opus-mt-en-zh\")\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"saved_model\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"./local_model/opus-mt-en-zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_texts(texts, model, tokenizer,  device):\n",
    "    # 对输入文本进行分词和编码\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "\n",
    "    # 使用模型生成翻译\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "    )\n",
    "\n",
    "    # 解码生成的翻译\n",
    "    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本: My god, that theme melody playing at the beginning... so nostalgic!\n",
      "翻译: 天哪,那个主题从一开始就在演奏... 如此怀旧!\n",
      "\n",
      "原始文本: My PC is sweating.\n",
      "翻译: 我的个人电脑在出汗。\n",
      "\n",
      "原始文本: Honestly using your best special forces in the slog of the Frontline in ukraine doesn't seem smart. In this conflict it doesn't matter how skilled you are as a soldier. You are just as likely to die as the freshly trained conscript next to you.  Special forces are going to be safer and more effective in places where they can play to their advantages.\n",
      "翻译: 在这场冲突中,你作为士兵的技巧并不重要。 你和旁边受过训练的应征士兵一样可能死去。\n",
      "\n",
      "原始文本: I've always been writing. Ever since I was three. I think we are all writing our own stories with every thought, word and action.\n",
      "翻译: 我从三岁起就一直在写作,我觉得我们都在用一切思想、语言和行动写故事。\n",
      "\n",
      "原始文本: As a lifelong sufferer of PTSD from an early childhood event...I just paused at 7:33 (with tears) because casting off old misperceptions of rejection is like another rejection in and of itself.  I have indeed been editing my story for several years now.   I know what I want my story to be.  You have just given me a window into a future that I can actually get to.  No.  More like an open door.  Thanks.\n",
      "翻译: ”作为一场早期童年活动中PTSD终身受难者,我刚刚在7点33分(带着泪水)停下来,因为抛弃对排斥的旧的误解就像是又一次自我排斥,我编辑我的故事已经有好几年时间了。 我知道自己的故事是怎样的。\n",
      "\n",
      "原始文本: I usually do something else while listening to ted talks or podcasts, but this one had me glued to the end\n",
      "翻译: 我通常在聆听Ted谈话或播客的同时做其他事情,但这一次却把我粘住了。\n",
      "\n",
      "原始文本: I think investors should always put their cash to work, especially In 2024, we'll start to see more market diversification. I'm hoping to invest about $350k of my savings in stocks against next year. Hope to make millions in 2024\n",
      "翻译: 我认为投资者应该永远将现金投入工作,特别是在2024年,我们将看到更多的市场多元化。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 示例输入文本\n",
    "texts = [\n",
    "  \"My god, that theme melody playing at the beginning... so nostalgic!\",\n",
    "  \"My PC is sweating.\",\n",
    "  \"Honestly using your best special forces in the slog of the Frontline in ukraine doesn't seem smart. In this conflict it doesn't matter how skilled you are as a soldier. You are just as likely to die as the freshly trained conscript next to you.  Special forces are going to be safer and more effective in places where they can play to their advantages.\",\n",
    "  \"I've always been writing. Ever since I was three. I think we are all writing our own stories with every thought, word and action.\",\n",
    "  \"As a lifelong sufferer of PTSD from an early childhood event...I just paused at 7:33 (with tears) because casting off old misperceptions of rejection is like another rejection in and of itself.  I have indeed been editing my story for several years now.   I know what I want my story to be.  You have just given me a window into a future that I can actually get to.  No.  More like an open door.  Thanks.\",\n",
    "  \"I usually do something else while listening to ted talks or podcasts, but this one had me glued to the end\",\n",
    "  \"I think investors should always put their cash to work, especially In 2024, we'll start to see more market diversification. I'm hoping to invest about $350k of my savings in stocks against next year. Hope to make millions in 2024\"\n",
    "]\n",
    "\n",
    "# 进行翻译\n",
    "translations = translate_texts(texts, model, tokenizer, device)\n",
    "\n",
    "# 打印翻译结果\n",
    "for text, translation in zip(texts, translations):\n",
    "    print(f\"原始文本: {text}\")\n",
    "    print(f\"翻译: {translation}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_text(text):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    translations = translate_texts([text], model, tokenizer, device)\n",
    "    return translations[0]\n",
    "\n",
    "\n",
    "# 创建 Gradio 接口\n",
    "iface = gr.Interface(\n",
    "    fn=translate_text,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"文本翻译\",\n",
    "    description=\"输入英文文本，获取中文翻译结果\"\n",
    ")\n",
    "\n",
    "# 启动 Gradio 接口\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
