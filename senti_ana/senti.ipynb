{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：100000\n",
      "评论数目（正向）：50000\n",
      "评论数目（负向）：50000\n",
      "        label                                             review\n",
      "17431       1                           [哈哈] 生日快乐！@偏心公公 @lilyli鑫\n",
      "37773       1  [哈哈]争画家的指点到位，平常没怎么注意，这小子给了惊喜。 //@油画家Artistlee李...\n",
      "27675       1  //@张新民: 回复@timesdance:不是不可以，凤凰炸豆干有好几种蘸料可选择，其中一...\n",
      "42674       1  [微风]去春游？“趣”春游！#长峰童鞋#们，现在大家尽炫自我的机会到了！4月16日前，炫出你...\n",
      "109202      0  我擦 //@风间小卒: @徐宝瑟  小心啦，担心的事情要发生了。 //@名犬杂志社:为什么五...\n",
      "113735      0        //@张?://@小乖乖麻麻: 昨天去金山市场就看见这位老爷爷举牌再找，好可怜！[泪]\n",
      "114564      0                           暹罗猫就是永远训不出来的节奏！！脾气忒大！[泪]\n",
      "79963       0  回复@Seven快点实现梦想吧:?是才?。//@Seven快点实现梦想吧:蔡生我觉得赚钱好慢...\n",
      "90862       0                           唉！这年头啊！现在滴小孩真滴是伤不起啊![抓狂]\n",
      "25568       1  路边社最新消息，@光辉Ken 最#适合开的车#居然是【人力三轮车】，被我发现了[哈哈] @小...\n"
     ]
    }
   ],
   "source": [
    "data = \"./weibo_senti_100k.csv\"\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "pd_all = pd.read_csv(data, encoding='utf-8')\n",
    "\n",
    "pd_positive = pd_all[pd_all.label==1]\n",
    "pd_negative = pd_all[pd_all.label==0]\n",
    "\n",
    "def get_balance_corpus(corpus_size, corpus_pos, corpus_neg):\n",
    "    sample_size = corpus_size // 2\n",
    "    pd_corpus_balance = pd.concat([corpus_pos.sample(sample_size, replace=corpus_pos.shape[0]<sample_size), \\\n",
    "                                   corpus_neg.sample(sample_size, replace=corpus_neg.shape[0]<sample_size)])\n",
    "    \n",
    "    print('评论数目（总体）：%d' % pd_corpus_balance.shape[0])\n",
    "    print('评论数目（正向）：%d' % pd_corpus_balance[pd_corpus_balance.label==1].shape[0])\n",
    "    print('评论数目（负向）：%d' % pd_corpus_balance[pd_corpus_balance.label==0].shape[0])    \n",
    "    \n",
    "    return pd_corpus_balance\n",
    "\n",
    "pd_all_balance = get_balance_corpus(100000, pd_positive, pd_negative)\n",
    "\n",
    "print(pd_all_balance.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\YetGirt\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.451 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                             review\n",
      "33823       1                            哈哈 电影 大鱼 小说 版 没 看过 这点 转\n",
      "30401       1                                祝福 祝福 百年好合 鼓掌 鼓掌 鼓掌\n",
      "31567       1  一大早 收到 哥哥 生日 祝福 开心 今天 农历 生日 下周一 阳历 生日 二十五 咯 不能...\n",
      "72388       0  泪 陈倩冰 泪毛 大庆 看了又看 潸然泪下 雅昌 艺术网 官方 微博 摄影 世界 这是 一个...\n",
      "113031      0         死 老外 滚 出 中国 胡爷 励志 成为 女人 怒 文章 同人肉 丫 见 一次 一次\n",
      "86442       0                                   转发 知道 全球 创意 搜罗 衰\n",
      "55064       1  我刚 完 往复 评论 站 准备 扯 站 老 嬉皮 Pop 哈哈 捶 黄初 三年 仔细 完 往...\n",
      "90088       0  这点 出门 走 分钟 没有 走出 我家 大门 我家 不住 故宫 点 之前 没到 真心 不能 ...\n",
      "106555      0  大概 名 没能 出镜 负责 棚内 具体 生产 工作 大姐 包装 车间 大姐 负责 配送 司机...\n",
      "2399        1                                           颜色 稍暗 嘻嘻\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    # 确保文本是字符串类型\n",
    "    text = str(text)\n",
    "    # 去除HTML标签\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # 替换特殊字符和数字\n",
    "    text = re.sub(r'[\\r|\\n|\\\\|0-9]', '', text)\n",
    "    # 去除标点\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 中文分词\n",
    "def chinese_tokenization(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "# 去除停用词\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words_filtered = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words_filtered)\n",
    "\n",
    "pd_all_balance['review'] = pd_all_balance['review'].apply(clean_text)\n",
    "\n",
    "pd_all_balance['review'] = pd_all_balance['review'].apply(chinese_tokenization)\n",
    "\n",
    "stopwords = set(open('cn_stopwords.txt', 'r', encoding='utf-8').read().split())\n",
    "\n",
    "pd_all_balance['review'] = pd_all_balance['review'].apply(remove_stopwords)\n",
    "\n",
    "print(pd_all_balance.sample(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16594    最近 带 两种 茶 铁观音 金骏眉 铁观音 属木 颜色 绿 兰花 香 金骏眉 感觉 属土 味...\n",
      "57597                                        最后 一张 亮 嘻嘻 嘻嘻\n",
      "44497        明星 李晨 今晚 住 朗廷 扬子 太 开心 激动 有木有 太 开心 兴奋 有木有 太 开心\n",
      "58905      康 家村 村长 哈哈 早 知道 签名 哈哈 康 家村 村长 真 幸运 出门 碰见 高晓松 表哥\n",
      "44440                                        名不虚传 国片 经典 哈哈\n",
      "Name: review, dtype: object\n",
      "tensor([[ 101, 3297, 6818, 2372,  697, 4905, 5763, 7188, 6225, 7509, 7032, 7742,\n",
      "         4691, 7188, 6225, 7509, 2247, 3312, 7582, 5682, 5344, 1065, 5709, 7676,\n",
      "         7032, 7742, 4691, 2697, 6230, 2247, 1759,  102],\n",
      "        [ 101, 3297, 1400,  671, 2476,  778, 1677, 1677, 1677, 1677,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 3209, 3215, 3330, 3247,  791, 3241,  857, 3306, 2455, 2813, 2094,\n",
      "         1922, 2458, 2552, 4080, 1220, 3300, 3312, 3300, 1922, 2458, 2552, 1069,\n",
      "         1939, 3300, 3312, 3300, 1922, 2458, 2552,  102],\n",
      "        [ 101, 2434, 2157, 3333, 3333, 7270, 1506, 1506, 3193, 4761, 6887, 5041,\n",
      "         1399, 1506, 1506, 2434, 2157, 3333, 3333, 7270, 4696, 2401, 6817, 1139,\n",
      "         7305, 4821, 6224, 7770, 3236, 3351, 6134,  102],\n",
      "        [ 101, 1399,  679, 5994,  837, 1744, 4275, 5307, 1073, 1506, 1506,  102,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path = './cache/'\n",
    "\n",
    "max_sequence_length = 32\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# 对文本进行分词和转换\n",
    "tokenized_texts = [tokenizer.encode(text, max_length=max_sequence_length, truncation=True) for text in pd_all_balance['review']]\n",
    "\n",
    "print(pd_all_balance['review'][:5])\n",
    "# print(tokenized_texts[:5])\n",
    "\n",
    "# 获取标签\n",
    "labels = pd_all_balance['label'].values\n",
    "\n",
    "# 手动实现数据的padding\n",
    "# 找出最长的序列长度\n",
    "max_len = max_sequence_length\n",
    "\n",
    "# 将所有序列padding到最长的序列长度\n",
    "padded_sequences = []\n",
    "for seq in tokenized_texts:\n",
    "    if len(seq) < max_len:\n",
    "        padded_seq = seq + [tokenizer.pad_token_id] * (max_len - len(seq))\n",
    "    else:\n",
    "        padded_seq = seq[:max_len]\n",
    "    padded_sequences.append(padded_seq)\n",
    "\n",
    "# 转换为PyTorch tensor\n",
    "X_data = torch.tensor(padded_sequences, dtype=torch.long)\n",
    "y_data = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "print(X_data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.X[idx]\n",
    "        attention_mask = (input_ids != 0).float()  # 生成 attention_mask\n",
    "        labels = self.y[idx]\n",
    "        return input_ids, attention_mask, labels\n",
    "\n",
    "# 划分数据集\n",
    "train_size = int(0.9 * len(X_data))\n",
    "val_size = len(X_data) - train_size\n",
    "\n",
    "train_dataset = TextDataset(X_data[:train_size], y_data[:train_size])\n",
    "val_dataset = TextDataset(X_data[train_size:], y_data[train_size:])\n",
    "\n",
    "# 定义DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs, device):\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "        \n",
    "        for inputs, attention_mask, labels in progress_bar:\n",
    "            inputs = inputs.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs,attention_mask)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() \n",
    "\n",
    "            predicted = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix({'train_loss': loss.item()})\n",
    "\n",
    "            writer.add_scalar('Loss/train', loss.item(), epoch+1)\n",
    "        \n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_correct = 0\n",
    "        total_valid = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, attention_mask, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                outputs = model(inputs, attention_mask)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                valid_loss += loss.item()\n",
    "                predicted = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                total_valid += labels.size(0)\n",
    "\n",
    "                writer.add_scalar('Loss/valid', loss.item(), epoch+1)\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        train_acc = (train_correct / total_train) * 100\n",
    "        valid_acc = (valid_correct / total_valid) * 100\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f} %,\\\n",
    "              Valid Loss: {valid_loss:.3f}, Valid Acc: {valid_acc:.2f} %')\n",
    "        \n",
    "\n",
    "        torch.save(model.state_dict(), f'./model/model_{epoch+1}.pth')\n",
    "        \n",
    "        # 保存最好的模型\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), './model/best_model.pth')\n",
    "            print('Best model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./cache were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48def218794b442d81311a3dcc4f401f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13536\\3826601392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# 开始训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13536\\2425147454.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, valid_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 修改模型结构\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, output_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # 取每个句子的第一个token的隐藏状态作为池化输出\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "output_dim = 1\n",
    "num_epochs = 5\n",
    "learning_rate = 5e-6\n",
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "# 加载预训练的BERT模型和分词器\n",
    "model_path = \"./cache\"\n",
    "# pretrained_model = BertModel.from_pretrained(model_path)\n",
    "\n",
    "# 实例化模型\n",
    "model = SentimentClassifier(model_path, output_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 开始训练\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./cache/ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SentimentClassifier:\n\tMissing key(s) in state_dict: \"bert.embeddings.position_ids\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13536\\3478898328.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 如果使用CPU进行推理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1672\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SentimentClassifier:\n\tMissing key(s) in state_dict: \"bert.embeddings.position_ids\". "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# 定义情感分析模型路径和其他参数\n",
    "model_path = \"./cache/\"\n",
    "path = \"./model/model_4.pth\"\n",
    "# tokenizer = BertTokenizer.from_pretrained('')\n",
    "max_sequence_length = 32 \n",
    "\n",
    "# 加载情感分析模型\n",
    "device = torch.device('cpu')  # 如果使用CPU进行推理\n",
    "model = SentimentClassifier(model_path, output_dim=1)\n",
    "model.load_state_dict(torch.load(path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 推理函数\n",
    "def infer_sentiment(comments):\n",
    "\n",
    "    comments = comments.splitlines()\n",
    "\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    total_comments = len(comments)\n",
    "    results = []\n",
    "\n",
    "    for comment in comments:\n",
    "        clean_comment = clean_text(comment.strip())  # 清理评论文本\n",
    "        tokenized_comment = chinese_tokenization(clean_comment)\n",
    "        final_comment = remove_stopwords(tokenized_comment)\n",
    "        tokenized_comment = tokenizer(final_comment, padding='max_length', truncation=True, max_length=max_sequence_length)\n",
    "        input_ids = tokenized_comment['input_ids']\n",
    "        attention_mask = tokenized_comment['attention_mask']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = torch.tensor([input_ids]).to(device)\n",
    "            attention_mask = torch.tensor([attention_mask]).to(device)\n",
    "\n",
    "            result = model(input_ids, attention_mask)\n",
    "            probabilities = torch.sigmoid(result)\n",
    "            predicted_class = (probabilities >= 0.5).item()\n",
    "\n",
    "            sentiment = 'Positive' if predicted_class == 1 else 'Negative'\n",
    "\n",
    "            if sentiment == 'Positive':\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                negative_count += 1\n",
    "\n",
    "            results.append({\n",
    "                \"评论\": comment,\n",
    "                \"情感概率\": f\"{probabilities.item():.3f}\",\n",
    "                \"情感分类\": sentiment\n",
    "            })\n",
    "\n",
    "    positive_percentage = (positive_count / total_comments) * 100\n",
    "    negative_percentage = (negative_count / total_comments) * 100\n",
    "\n",
    "    return total_comments, positive_count, f\"{positive_percentage:.2f}%\", negative_count, f\"{negative_percentage:.2f}%\"\n",
    "\n",
    "# Gradio 界面设置\n",
    "iface = gr.Interface(\n",
    "    fn=infer_sentiment,\n",
    "    inputs=gr.Textbox(label=\"输入评论（每行一个）\", type=\"text\", lines=15),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"总评论数\", type=\"text\"),\n",
    "        gr.Textbox(label=\"积极情绪句子数量\", type=\"text\"),\n",
    "        gr.Textbox(label=\"积极情绪百分比\", type=\"text\"),\n",
    "        gr.Textbox(label=\"消极情绪句子数量\", type=\"text\"),\n",
    "        gr.Textbox(label=\"消极情绪百分比\", type=\"text\")\n",
    "    ],\n",
    "    title=\"评论情感分析\",\n",
    "    description=\"输入多条评论，进行情感分析，统计积极和消极情绪数量及百分比。\"\n",
    ")\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "iface.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
