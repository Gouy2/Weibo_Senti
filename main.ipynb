{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：100000\n",
      "评论数目（正向）：50000\n",
      "评论数目（负向）：50000\n",
      "       label                                             review\n",
      "31245      1  羡慕、嫉妒不恨！[嘻嘻] //@红星闪啊闪啊闪:哇塞，帅 //@旅伴箩箩-罗军: @奥神刘来...\n",
      "36894      1               来呀来呀[可爱][可爱] //@Beryl-冰sunshine:转发微博\n",
      "11404      1  阿布吉目前倒是定期照，可是十几岁以后粑粑就要抱不动了吧[哈哈] //@蜜思李珊珊珊:有女儿的...\n",
      "17791      1                 这个可以有//@-罗大宁宁的小学妹er--: 是不是傻哈哈哈[哈哈]\n",
      "87170      0  回复@柳树家的:我发现是瓶盖没拧好，斜着拧上的，包是黑的，倒是看不出来，主要是包里有条围巾，...\n",
      "23777      1  [哈哈]开心！@我是王大磊大力相助解决了票务问题！孙氏剪纸捧回家来！特别隆重值得纪录：前日收...\n",
      "3383       1  好主意[鼓掌]看来等我女儿长大了也送套厨房算了，房价实在太高了@xin_may[偷笑][偷笑...\n",
      "39365      1                              有缘下次还会再见的[握手][鼓掌][鼓掌]\n",
      "12006      1                        留个备用！[嘻嘻] //@红星闪闪大黑豆来了:转发微博\n",
      "23536      1                                           [嘻嘻]好高大上\n"
     ]
    }
   ],
   "source": [
    "# data = \"./ChnSentiCorp_htl_all.csv\"\n",
    "data = \"./weibo_senti_100k.csv\"\n",
    "\n",
    "pd_all = pd.read_csv(data, encoding='utf-8')\n",
    "\n",
    "pd_positive = pd_all[pd_all.label==1]\n",
    "pd_negative = pd_all[pd_all.label==0]\n",
    "\n",
    "def get_balance_corpus(corpus_size, corpus_pos, corpus_neg):\n",
    "    sample_size = corpus_size // 2\n",
    "    pd_corpus_balance = pd.concat([corpus_pos.sample(sample_size, replace=corpus_pos.shape[0]<sample_size), \\\n",
    "                                   corpus_neg.sample(sample_size, replace=corpus_neg.shape[0]<sample_size)])\n",
    "    \n",
    "    print('评论数目（总体）：%d' % pd_corpus_balance.shape[0])\n",
    "    print('评论数目（正向）：%d' % pd_corpus_balance[pd_corpus_balance.label==1].shape[0])\n",
    "    print('评论数目（负向）：%d' % pd_corpus_balance[pd_corpus_balance.label==0].shape[0])    \n",
    "    \n",
    "    return pd_corpus_balance\n",
    "\n",
    "pd_all_balance = get_balance_corpus(100000, pd_positive, pd_negative)\n",
    "\n",
    "print(pd_all_balance.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\YetGirt\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.469 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                             review\n",
      "45634      1  嘻嘻 食神 咖喱 牛腩 鲍鱼 金汤 牛腩 面 冰火 岛 深海 龙虾 手 擀 凉面 威武 三款...\n",
      "40931      1                                           接下去 鼓掌 力\n",
      "20069      1  诬蔑 中 吴 晨光 中大 谈乱 爱 何江涛 中大 女生 富裕 一个 嘻嘻 光头 三爷 难 清...\n",
      "57548      1                               可爱 柳絮 满天飞 应该 看看 耶 哈哈\n",
      "91149      0                                   拜拜 北京 泪 首都 模式 开启\n",
      "36513      1  芒果 免费送 澳洲 太 开心 阳光 海岸边 想 慕容 小妖精 mmno 许磊 人注 MS 贝...\n",
      "53481      1  帅 QPlus 产品 团队 Q 壁纸 库 精美壁纸 心情 更换 w 网址 导航 WEB Q ...\n",
      "14825      1  哈哈 谢谢 支持 爱 Nicole Gu 世界 金陵 豪包 高大 嘻嘻 嘻嘻 黄浩俊 How...\n",
      "89452      0               衰 北京 知道 北京 事儿 跑 水 地儿 燕莎 桥下 目前 对主路 影响\n",
      "61447      0              一天 屎尿 屁 没干 为啥 一个 辣 生物 会 蕴藏 辣 丰富 泪泪 泪泪\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    # 确保文本是字符串类型\n",
    "    text = str(text)\n",
    "    # 去除HTML标签\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # 替换特殊字符和数字\n",
    "    text = re.sub(r'[\\r|\\n|\\\\|0-9]', '', text)\n",
    "    # 去除标点\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 中文分词\n",
    "def chinese_tokenization(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "# 去除停用词\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words_filtered = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words_filtered)\n",
    "\n",
    "pd_all_balance['review'] = pd_all_balance['review'].apply(clean_text)\n",
    "\n",
    "pd_all_balance['review'] = pd_all_balance['review'].apply(chinese_tokenization)\n",
    "\n",
    "stopwords = set(open('cn_stopwords.txt', 'r', encoding='utf-8').read().split())\n",
    "\n",
    "pd_all_balance['review'] = pd_all_balance['review'].apply(remove_stopwords)\n",
    "\n",
    "print(pd_all_balance.sample(10))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index saved to word_index.json\n",
      "词汇量：189005\n",
      "训练集大小：80000\n",
      "[[  56  496 1982    3   64    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  15  593   69 2688  232 1319  117  206 1496   36  136 1316 1433   16\n",
      "    29   16]\n",
      " [  71    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 设置最大词汇量和序列长度\n",
    "vocab_size = 5000\n",
    "max_sequence_length = 16\n",
    "min_word_frequency = 10\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(pd_all_balance['review'])\n",
    "\n",
    "# # 计算每个词的频率并过滤掉低频词\n",
    "# filtered_words = {word: index for word, index in tokenizer.word_index.items() if tokenizer.word_counts[word] >= min_word_frequency}\n",
    "# # 更新tokenizer的词汇表\n",
    "# tokenizer.word_index = filtered_words\n",
    "# tokenizer.num_words = len(filtered_words)\n",
    "\n",
    "# 获取词汇表\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 保存词汇表到JSON文件\n",
    "with open('word_index.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(word_index, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Word index saved to word_index.json\")\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(pd_all_balance['review'])\n",
    "\n",
    "print('词汇量：%d' % len(tokenizer.word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# 划分数据集\n",
    "labels = pd_all_balance['label'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print('训练集大小：%d' % len(X_train))\n",
    "print(X_val[:3])\n",
    "print(y_val[:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "val_dataset = TextDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, hidden_dim, num_layers, output_dim, dropout=0.2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_encoding = self.create_positional_encoding(max_len=16)  \n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, output_dim)\n",
    "\n",
    "    def create_positional_encoding(self, max_len):\n",
    "        # 创建位置编码\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        i = torch.arange(0, self.embed_size, 2).float()\n",
    "        angle_rates = 1 / torch.pow(10000, (i / self.embed_size))\n",
    "        pos_encoding = torch.zeros(max_len, self.embed_size)\n",
    "        pos_encoding[:, 0::2] = torch.sin(pos * angle_rates)\n",
    "        pos_encoding[:, 1::2] = torch.cos(pos * angle_rates)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)\n",
    "        return nn.Parameter(pos_encoding, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x) + self.positional_encoding[:, :x.size(1)]\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f2eab011de41268511cccb67d83c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22892\\2163471257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;31m# 开始训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22892\\2163471257.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, valid_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs, device):\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "        \n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() \n",
    "\n",
    "            predicted = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix({'train_loss': loss.item()})\n",
    "        \n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_correct = 0\n",
    "        total_valid = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                valid_loss += loss.item()\n",
    "                predicted = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                total_valid += labels.size(0)\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        train_acc = (train_correct / total_train) * 100\n",
    "        valid_acc = (valid_correct / total_valid) * 100\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f} %,\\\n",
    "              Valid Loss: {valid_loss:.3f}, Valid Acc: {valid_acc:.2f} %')\n",
    "        \n",
    "\n",
    "        torch.save(model.state_dict(), f'model_{epoch+1}.pth')\n",
    "        \n",
    "        # 保存最好的模型\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print('Best model saved')\n",
    "\n",
    "\n",
    "embed_size = 256\n",
    "num_heads = 4\n",
    "hidden_dim = 512\n",
    "num_layers = 4\n",
    "output_dim = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerModel(vocab_size, embed_size, num_heads, hidden_dim, num_layers, output_dim)\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 开始训练\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: tensor([[2300,  865,   80,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "data: tensor([[1118,  247,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "data: tensor([[178,  36, 585,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0]])\n",
      "data: tensor([[585,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0]])\n",
      "评论: 优秀的女孩[赞]\n",
      "情感概率: 0.512\n",
      "情感分类: 积极\n",
      "\n",
      "评论: 中专女生，那她得多努力才行[泪]\n",
      "情感概率: 0.536\n",
      "情感分类: 积极\n",
      "\n",
      "评论: 我的天哪，这个是真的很厉害\n",
      "情感概率: 0.525\n",
      "情感分类: 积极\n",
      "\n",
      "评论: 好厉害\n",
      "情感概率: 0.518\n",
      "情感分类: 积极\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_size = 256\n",
    "num_heads = 4\n",
    "hidden_dim = 512\n",
    "num_layers = 4\n",
    "output_dim = 1\n",
    "num_epochs = 10\n",
    "\n",
    "# text = \"\"\n",
    "\n",
    "# path = \"./model_2.pth\"\n",
    "# path = \"./best_model.pth\"\n",
    "path = \"./model_3.pt\"\n",
    "\n",
    "\n",
    "model = TransformerModel(vocab_size, embed_size, num_heads, hidden_dim, num_layers, output_dim)\n",
    "# model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "model = torch.load(path, map_location='cpu')\n",
    "model.eval()\n",
    "\n",
    "with open('comments.txt', 'r', encoding='utf-8') as file:\n",
    "    comments = file.readlines()\n",
    "\n",
    "# 存储结果\n",
    "results = []\n",
    "\n",
    "# 处理每个评论并进行推理\n",
    "for comment in comments:\n",
    "    clean_comment = clean_text(comment.strip())\n",
    "    tokenized_comment = chinese_tokenization(clean_comment)\n",
    "    final_comment = remove_stopwords(tokenized_comment)\n",
    "    # print(\"final_comment:\",final_comment)\n",
    "    sequences = tokenizer.texts_to_sequences([final_comment])\n",
    "\n",
    "    # print(\"sequences:\",sequences)\n",
    "    data = pad_sequences(sequences, maxlen=16, padding='post')\n",
    "\n",
    "    \n",
    "\n",
    "    data = torch.tensor(data, dtype=torch.long)\n",
    "\n",
    "    print(\"data:\",data)\n",
    "\n",
    "    # 转换为Tensor并输入模型\n",
    "    result = model(data)\n",
    "    probabilities = torch.sigmoid(result)\n",
    "    predicted_classes = (probabilities >= 0.5).int()\n",
    "    \n",
    "    # 存储结果\n",
    "    results.append((comment.strip(), probabilities.item(), '积极' if predicted_classes.item() == 1 else '消极'))\n",
    "\n",
    "# 输出或保存结果\n",
    "for comment, prob, sentiment in results:\n",
    "    print(f\"评论: {comment}\\n情感概率: {prob:.3f}\\n情感分类: {sentiment}\\n\")\n",
    "\n",
    "# 保存结果到文件\n",
    "with open('comments_with_sentiments.txt', 'w', encoding='utf-8') as file:\n",
    "    for comment, prob, sentiment in results:\n",
    "        file.write(f\"评论: {comment}\\n情感概率: {prob:.3f}\\n情感分类: {sentiment}\\n\\n\")\n",
    "\n",
    "\n",
    "# clean = clean_text(text)\n",
    "\n",
    "# print(\"清理后：\" ,clean)\n",
    "\n",
    "# tokenized = chinese_tokenization(clean)\n",
    "\n",
    "# print(\"分词后：\" ,tokenized)\n",
    "\n",
    "# final_text = remove_stopwords(tokenized)\n",
    "\n",
    "# print(\"去除停用词：\" ,final_text)\n",
    "\n",
    "# sequences = tokenizer.texts_to_sequences([final_text])\n",
    "# data = pad_sequences(sequences, maxlen=32, padding='post')\n",
    "\n",
    "# print(\"数字序列：\",data)\n",
    "\n",
    "# result = model(torch.tensor(data))\n",
    "# probabilities = torch.sigmoid(result)\n",
    "# predicted_classes = (probabilities >= 0.5).int()\n",
    "# # print(\"probabilities:\",0.973)\n",
    "# # print(\"predicted_classes:\",\"积极\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\gradio\\inputs.py:28: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n",
      "d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\gradio\\inputs.py:37: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  optional=optional,\n",
      "d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\gradio\\inputs.py:37: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  optional=optional,\n",
      "d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\gradio\\outputs.py:198: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  \"Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\",\n",
      "d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\gradio\\outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gradio as gr\n",
    "\n",
    "# embed_size = 256\n",
    "# num_heads = 4\n",
    "# hidden_dim = 512\n",
    "# num_layers = 4\n",
    "# output_dim = 1\n",
    "# num_epochs = 10\n",
    "# learning_rate = 1e-4\n",
    "# weight_decay = 1e-4\n",
    "\n",
    "\n",
    "# path = 'model_3.pth'\n",
    "# model = TransformerModel(vocab_size, embed_size, num_heads, hidden_dim, num_layers, output_dim)\n",
    "# # model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# def predict(text):\n",
    "#     clean = clean_text(text)\n",
    "#     tokenized = chinese_tokenization(clean)\n",
    "#     final_text = remove_stopwords(tokenized)\n",
    "#     sequences = tokenizer.texts_to_sequences([final_text])\n",
    "#     data = pad_sequences(sequences, maxlen=16, padding='post')\n",
    "#     result = model(torch.tensor(data))\n",
    "#     probabilities = torch.sigmoid(result)\n",
    "#     sentiment = \"积极\" if probabilities >= 0.5 else \"消极\"\n",
    "#     return {\"Sentiment\": sentiment, \"Probability\": float(probabilities)}\n",
    "\n",
    "# iface = gr.Interface(\n",
    "#     fn=predict,\n",
    "#     inputs=gr.inputs.Textbox(lines=4, placeholder=\"Enter Text Here...\"),\n",
    "#     outputs=[\n",
    "#         gr.outputs.Label(num_top_classes=2)\n",
    "#     ],\n",
    "#     title=\"情感分析\",\n",
    "#     description=\"输入你的句子，我们将预测它的情感。\"\n",
    "# )\n",
    "\n",
    "# iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\YetGirt\\AppData\\Local\\Temp\\ipykernel_21728\\3875919683.py\", line 70, in load_model_dialog\n",
      "    model = load_model(filepath)\n",
      "  File \"C:\\Users\\YetGirt\\AppData\\Local\\Temp\\ipykernel_21728\\3875919683.py\", line 16, in load_model\n",
      "    model.load_state_dict(torch.load(path, map_location='cpu'))\n",
      "  File \"d:\\Programs\\miniconda3\\envs\\d2l_stu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1672, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for TransformerModel:\n",
      "\tsize mismatch for transformer.layers.0.linear1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
      "\tsize mismatch for transformer.layers.0.linear1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for transformer.layers.0.linear2.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n",
      "\tsize mismatch for transformer.layers.1.linear1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
      "\tsize mismatch for transformer.layers.1.linear1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for transformer.layers.1.linear2.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n",
      "\tsize mismatch for transformer.layers.2.linear1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
      "\tsize mismatch for transformer.layers.2.linear1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for transformer.layers.2.linear2.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n",
      "\tsize mismatch for transformer.layers.3.linear1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
      "\tsize mismatch for transformer.layers.3.linear1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for transformer.layers.3.linear2.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摊上大事了 曹增辉 衰 衰 这个太悲剧了\n",
      "摊上 大事 曹 增辉 衰 衰 太 悲剧\n",
      "[[4307 2222   16   16    8 1449    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "result:  tensor([[0.0291]], grad_fn=<AddmmBackward0>)\n",
      "Probability: 0.507, Predicted Class: 1\n",
      "微博电影送福利 已点赞可爱那些岁月我们一起爱着的中国好声音可爱记得中国好声音的节目热播期间选手的表现和特质成了周围很多同事特别关心的话题而我自己看完第一时间播出的节目后还不满足还看了很多重播那不仅仅是中国好声音更是中国很多被埋没的好声音凤凰涅的中国梦\n",
      "微博 电影 送 福利 已点 赞 可爱 岁月 一起 爱着 中国 声音 可爱 记得 中国 声音 节目 热播 期间 选手 表现 特质 成 周围 很多 同事 特别 关心 话题 完 第一 时间 播出 节目 满足 很多 重播 不仅仅 中国 声音 更是 中国 很多 埋没 声音 凤凰 涅 中国 梦\n",
      "[[1306  239 1798  130 4155 5880   27  501 1761   27  130  501 1371 5593\n",
      "    27  472]]\n",
      "result:  tensor([[0.1195]], grad_fn=<AddmmBackward0>)\n",
      "Probability: 0.530, Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# import tkinter as tk\n",
    "# from tkinter import filedialog,font\n",
    "\n",
    "# embed_size = 256\n",
    "# num_heads = 8\n",
    "# hidden_dim = 1024\n",
    "# num_layers = 4\n",
    "# output_dim = 1\n",
    "# num_epochs = 10\n",
    "# learning_rate = 5e-5\n",
    "# weight_decay = 1e-5\n",
    "\n",
    "\n",
    "# def load_model(path):\n",
    "#     model = TransformerModel(vocab_size, embed_size, num_heads, hidden_dim, num_layers, output_dim)\n",
    "#     model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "#     model.eval()\n",
    "#     return model\n",
    "\n",
    "# def infer():\n",
    "#     # 获取输入并进行预处理\n",
    "#     raw_text = text_entry.get()\n",
    "#     clean = clean_text(raw_text)\n",
    "\n",
    "#     print(clean)\n",
    "\n",
    "#     tokenized = chinese_tokenization(clean)\n",
    "#     final_text = remove_stopwords(tokenized)\n",
    "\n",
    "#     print(final_text)\n",
    "\n",
    "#     sequences = tokenizer.texts_to_sequences([final_text])\n",
    "#     data = pad_sequences(sequences, maxlen=16, padding='post')\n",
    "\n",
    "#     print(data)\n",
    "\n",
    "#     if model:\n",
    "#         result = model(torch.tensor(data))\n",
    "#         probabilities = torch.sigmoid(result)\n",
    "#         predicted_classes = (probabilities >= 0.5).int()\n",
    "#         result_label.config(text=f\"Probability: {probabilities.item():.3f}, Predicted Class: {predicted_classes.item()}\")\n",
    "\n",
    "#         print(\"result: \", result)\n",
    "\n",
    "#         print(f\"Probability: {probabilities.item():.3f}, Predicted Class: {predicted_classes.item()}\")\n",
    "        \n",
    "#     else:\n",
    "#         result_label.config(text=\"Please load a model first.\")\n",
    "\n",
    "\n",
    "# # 创建主窗口\n",
    "# root = tk.Tk()\n",
    "# root.title(\"Sentiment Analysis\")\n",
    "# root.configure(bg='#f0f0f0')  # 设置背景颜色\n",
    "\n",
    "# # 定义一些美化的样式\n",
    "# large_font = font.Font(family=\"Helvetica\", size=14, weight=\"bold\")\n",
    "# button_font = font.Font(family=\"Helvetica\", size=12)\n",
    "# label_font = font.Font(family=\"Helvetica\", size=12)\n",
    "\n",
    "# # 创建一个文本输入框\n",
    "# text_entry = tk.Entry(root, font=large_font, width=50)\n",
    "# text_entry.pack(pady=20)\n",
    "\n",
    "# # 选择模型文件\n",
    "# def load_model_dialog():\n",
    "#     filepath = filedialog.askopenfilename()\n",
    "#     model_label.config(text=f\"模型: {filepath.split('/')[-1]}\")\n",
    "#     global model\n",
    "#     model = load_model(filepath)\n",
    "\n",
    "# model_button = tk.Button(root, text=\"加载模型\", command=load_model_dialog, font=button_font, bg='#dfe3ee', fg='black')\n",
    "# model_button.pack(pady=10)\n",
    "\n",
    "# model_label = tk.Label(root, text=\"No Model\", font=label_font, bg='#f0f0f0', fg='red')\n",
    "# model_label.pack(pady=5)\n",
    "\n",
    "# infer_button = tk.Button(root, text=\"分析情感\", command=infer, font=button_font, bg='#dfe3ee', fg='black')\n",
    "# infer_button.pack(pady=10)\n",
    "\n",
    "# # 显示结果的标签\n",
    "# result_label = tk.Label(root, text=\"\", font=label_font, bg='#f0f0f0', fg='blue')\n",
    "# result_label.pack(pady=5)\n",
    "\n",
    "# # 运行主循环\n",
    "# root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l_stu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
